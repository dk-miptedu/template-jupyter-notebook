{"cells":[{"cell_type":"markdown","metadata":{"id":"o8Sj-ePGG176"},"source":["## Lab 2"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["!pip install tensorflow -q"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["!pip install matplotlib -q"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["!pip install TensorRT"]},{"cell_type":"code","execution_count":71,"metadata":{"metadata":{}},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch\n","  Downloading torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: filelock in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (4.11.0)\n","Collecting sympy (from torch)\n","  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch)\n","  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: jinja2 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from torch) (3.1.3)\n","Collecting fsspec (from torch)\n","  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n","Collecting mpmath>=0.19 (from sympy->torch)\n","  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n","Downloading torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:03\u001b[0mm\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m168.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m137.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mmm\n","\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n","    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n","Successfully installed fsspec-2024.3.1 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.3.0\n"]}],"source":["!pip install torch"]},{"cell_type":"markdown","metadata":{"id":"2b6OKqzkG17_"},"source":["### Part 3. Poetry generation\n","\n","Let's try to generate some poetry using RNNs.\n","\n","You have several choices here:\n","\n","* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n","\n","* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n","\n","* Some other text source, if it will be approved by the course staff.\n","\n","Text generation can be designed in several steps:\n","    \n","1. Data loading.\n","2. Dictionary generation.\n","3. Data preprocessing.\n","4. Model (neural network) training.\n","5. Text generation (model evaluation).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":566,"status":"ok","timestamp":1715086322156,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"dAdpijqkG18A","metadata":{}},"outputs":[],"source":["import string\n","import os"]},{"cell_type":"markdown","metadata":{"id":"N9Xrq3pcG18B"},"source":["### Data loading: Shakespeare"]},{"cell_type":"markdown","metadata":{"id":"Kg2cOI8-G18C"},"source":["Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715087956839,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"AMbwzlHRG18C","metadata":{}},"outputs":[],"source":["#if not os.path.exists('sonnets.txt'):\n","#    !wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/lab02_deep_learning/sonnets.txt\n","\n","#with open('sonnets.txt', 'r') as iofile:\n","#    text = iofile.readlines()\n","\n","#TEXT_START = 45\n","#TEXT_END = -368\n","#text = text[TEXT_START : TEXT_END]\n","#assert len(text) == 2616"]},{"cell_type":"markdown","metadata":{"id":"kvaT-wqyG18C"},"source":["In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n","\n","Now variable `text` is a list of strings. Join all the strings into one and lowercase it."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715087962450,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"5h_orjQ2G18D","metadata":{},"outputId":"0b513c08-4a50-434c-c49f-44312b57dc9a"},"outputs":[],"source":["# Join all the strings into one and lowercase it\n","# Put result into variable text.\n","\n","#text = ''.join(text).lower()# Your great code here\n","\n","#assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n","#assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n","#print('OK!')"]},{"cell_type":"markdown","metadata":{"id":"MQJgVrJJG18D"},"source":["### Data loading: \"Евгений Онегин\"\n"]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":698,"status":"ok","timestamp":1715086681689,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"Ot7G1nTlG18D","metadata":{},"outputId":"89b2225e-3817-43fa-fb3d-b31a0a546124"},"outputs":[],"source":["#!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n","\n","with open('onegin.txt', 'r') as iofile:\n","    text = iofile.readlines()\n","#text = ''.join(text).lower()\n","text = [x.replace('\\t\\t', '') for x in text]"]},{"cell_type":"code","execution_count":106,"metadata":{"metadata":{}},"outputs":[{"data":{"text/plain":["<function str.lower()>"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":["text[0].lower"]},{"cell_type":"code","execution_count":100,"metadata":{"metadata":{}},"outputs":[],"source":["chars = sorted(set(text))  # Get a sorted list of all unique characters\n","char_to_index = {ch: i for i, ch in enumerate(chars)}  # Character to index mapping\n","index_to_char = {i: ch for i, ch in enumerate(chars)}  # Index to character mapping\n"]},{"cell_type":"markdown","metadata":{"id":"Yn-0wCFbG18E"},"source":["In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n","\n","Now variable `text` is a list of strings. Join all the strings into one and lowercase it."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1715086687917,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"rZuTpu-dG18E","metadata":{}},"outputs":[],"source":["# Join all the strings into one and lowercase it\n","# Put result into variable text.\n","out = ''.join(text).lower()\n","\n","\n","# Your great code here\n"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["out"]},{"cell_type":"markdown","metadata":{"id":"ZUyE0sGOG18E"},"source":["Put all the characters, that you've seen in the text, into variable `tokens`."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715086692177,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"fXFGYnTqG18E","metadata":{}},"outputs":[],"source":["tokens = sorted(set(out))"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["tokens"]},{"cell_type":"markdown","metadata":{"id":"nfOfDRAyG18F"},"source":["Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":3,"status":"ok","timestamp":1715086741519,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"0GhcFGk8G18F","metadata":{}},"outputs":[],"source":["# dict <index>:<char>\n","# Your great code here\n","# Create a sorted list of unique characters\n","# Dictionary mapping index to character\n","idx_to_token = {index: char for index, char in enumerate(tokens)}\n","\n","# dict <char>:<index>\n","# Your great code here\n","# Dictionary mapping character to index\n","token_to_idx = {char: index for index, char in enumerate(tokens)}\n"]},{"cell_type":"markdown","metadata":{"id":"jfOs6oUHG18F"},"source":["*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"]},{"cell_type":"markdown","metadata":{"id":"20dOwhVJG18F"},"source":["### Building the model"]},{"cell_type":"markdown","metadata":{"id":"lKKN1DUfG18F"},"source":["Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n","\n","Let's use vanilla RNN, similar to the one created during the lesson."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":446,"status":"ok","timestamp":1715086780925,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"AW2OE5-3G18F","metadata":{}},"outputs":[],"source":["# Your code here\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n","from tensorflow.keras.callbacks import LambdaCallback\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["#sentences\n","[[item for item in sublist if item] for sublist in sentences]"]},{"cell_type":"code","execution_count":101,"metadata":{"executionInfo":{"elapsed":544,"status":"ok","timestamp":1715088164833,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"XUSxNPNJI2-u","metadata":{}},"outputs":[],"source":["# Assuming text is already loaded and preprocessed as in your snippet\n","\n","# Constants\n","MAXLEN = 40  # Length of extracted character sequences\n","STEP = 3  # Step size for moving the reading window\n","\n","\n","\n","# Cut the text in semi-redundant sequences of MAXLEN characters\n","sentences = []\n","next_chars = []\n","for i in range(0, len(text) - MAXLEN, STEP):\n","    sentences.append(text[i: i + MAXLEN])\n","    next_chars.append(text[i + MAXLEN])\n","sentences = [[item for item in sublist if item] for sublist in sentences]\n","# One-hot encoding\n","x = np.zeros((len(sentences), MAXLEN, len(chars)), dtype=np.bool_)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool_)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        if char in char_to_index:  # Check if the char is in the dictionary\n","            x[i, t, char_to_index[char]] = 1\n","        else:\n","            print(f\"Missing character in dictionary: {char}\")  # This will help identify any missing characters\n","    next_char = next_chars[i]\n","    if next_char in char_to_index:\n","        y[i, char_to_index[next_char]] = 1\n","    else:\n","        print(f\"Missing next character in dictionary: {next_char}\")\n","# Build the model: a single LSTM\n","model = Sequential([\n","    SimpleRNN(128, input_shape=(MAXLEN, len(chars))),\n","    Dense(len(chars), activation='softmax'),\n","])\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","# Helper function to sample an index from a probability array\n","def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","# Function invoked at end of each epoch to print generated text\n","def on_epoch_end(epoch, _):\n","    print()\n","    print('----- Generating text after Epoch: %d' % epoch)\n","\n","    start_index = np.random.randint(0, len(text) - MAXLEN - 1) \n","    generated = ''\n","    sentence = text[start_index: start_index + MAXLEN]\n","    sentence = ' '.join(sentence)\n","    #print(f'on_epoch_end sentence: {sentence}')\n","    generated += sentence\n","    print('----- Generating with seed: \"' + sentence + '\"')\n","    sys.stdout.write(generated)\n","\n","    for i in range(400):\n","        x_pred = np.zeros((1, MAXLEN, len(chars)))\n","        for t, char in enumerate(sentence):\n","            x_pred[0, t, char_indices[char]] = True\n","\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        next_index = sample(preds, temperature=1.0)\n","        next_char = indices_char[next_index]\n","\n","        generated += next_char\n","        sentence = sentence[1:] + next_char\n","\n","        sys.stdout.write(next_char)\n","        sys.stdout.flush()\n","    print()\n","\n","print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"metadata":{}},"outputs":[],"source":["start_index = np.random.randint(0, len(text) - MAXLEN - 1) \n","generated = ''\n","sentence = text[start_index: start_index + MAXLEN]\n","sentence = ' '.join(sentence)\n","print(f'on_epoch_end sentence: {sentence}')\n","generated += sentence\n","print('----- Generating with seed: \"' + sentence + '\"')\n","sys.stdout.write(generated)"]},{"cell_type":"code","execution_count":68,"metadata":{"metadata":{}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2024-05-11 17:26:08.007584: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 499704000 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 362ms/step - loss: 4.7089\n","Epoch 2/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 351ms/step - loss: 4.7901\n","Epoch 3/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - loss: 4.7529\n","Epoch 4/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 205ms/step - loss: 4.6432\n","Epoch 5/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - loss: 4.7693\n","Epoch 6/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - loss: 4.6782\n","Epoch 7/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - loss: 4.6242\n","Epoch 8/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 411ms/step - loss: 4.5931\n","Epoch 9/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 396ms/step - loss: 4.5394\n","Epoch 10/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 384ms/step - loss: 4.5579\n"]}],"source":["\n","history = model.fit(x, y, batch_size=128, epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"FQ5DGE2tG18F"},"source":["Plot the loss function (axis X: number of epochs, axis Y: loss function)."]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":1312434,"status":"ok","timestamp":1715092534836,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"qaLIjcYMG18F","metadata":{},"outputId":"73a3c8b4-5ef4-456e-e7fb-e04e349df25e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - loss: 8.4560\n","----- Generating text after Epoch: 0\n","----- Generating with seed: \"И, утренней луны бледней\n"," И трепетней гонимой лани,\n"," Она темнеющих очей\n"," Не подымает: пышет бурно\n"," В ней страстный жар; ей душно, дурно;\n"," Она приветствий двух друзей\n"," Не слышит, слезы из очей\n"," Хотят уж капать; уж готова\n"," Бедняжка в обморок упасть;\n"," Но воля и рассудка власть\n"," Превозмогли. Она два слова\n"," Сквозь зубы молвила тишком\n"," И усидела за столом.\n"," \n"," \n"," \n"," XXXI\n"," \n"," Траги-нервических явлений,\n"," Девичьих обмороков, слез\n"," Давно терпеть не мог Евгений:\n"," Довольно их он перенес.\n"," Чудак, попав на пир огромный,\n"," Уж был сердит. Но, девы томной\n"," Заметя трепетный порыв,\n"," С досады взоры опустив,\n"," Надулся он и, негодуя,\n"," Поклялся Ленского взбесить\n"," И уж порядком отомстить.\n"," Теперь, заране торжествуя,\n"," Он стал чертить в душе своей\n"," Карикатуры всех гостей.\n"," \n"," \n"," \n"," XXXII\n"," \n"," Конечно, не один Евгений\n"," Смятенье Тани видеть мог;\n"," Но целью взоров и суждений\n","\"\n","И, утренней луны бледней\n"," И трепетней гонимой лани,\n"," Она темнеющих очей\n"," Не подымает: пышет бурно\n"," В ней страстный жар; ей душно, дурно;\n"," Она приветствий двух друзей\n"," Не слышит, слезы из очей\n"," Хотят уж капать; уж готова\n"," Бедняжка в обморок упасть;\n"," Но воля и рассудка власть\n"," Превозмогли. Она два слова\n"," Сквозь зубы молвила тишком\n"," И усидела за столом.\n"," \n"," \n"," \n"," XXXI\n"," \n"," Траги-нервических явлений,\n"," Девичьих обмороков, слез\n"," Давно терпеть не мог Евгений:\n"," Довольно их он перенес.\n"," Чудак, попав на пир огромный,\n"," Уж был сердит. Но, девы томной\n"," Заметя трепетный порыв,\n"," С досады взоры опустив,\n"," Надулся он и, негодуя,\n"," Поклялся Ленского взбесить\n"," И уж порядком отомстить.\n"," Теперь, заране торжествуя,\n"," Он стал чертить в душе своей\n"," Карикатуры всех гостей.\n"," \n"," \n"," \n"," XXXII\n"," \n"," Конечно, не один Евгений\n"," Смятенье Тани видеть мог;\n"," Но целью взоров и суждений\n"]},{"ename":"KeyError","evalue":"'И'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[102], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Your plot code here\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Plotting the loss\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","Cell \u001b[0;32mIn[101], line 64\u001b[0m, in \u001b[0;36mon_epoch_end\u001b[0;34m(epoch, _)\u001b[0m\n\u001b[1;32m     62\u001b[0m x_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, MAXLEN, \u001b[38;5;28mlen\u001b[39m(chars)))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, char \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentence):\n\u001b[0;32m---> 64\u001b[0m     x_pred[\u001b[38;5;241m0\u001b[39m, t, \u001b[43mchar_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m]\u001b[49m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     66\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_pred, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m next_index \u001b[38;5;241m=\u001b[39m sample(preds, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n","\u001b[0;31mKeyError\u001b[0m: 'И'"]}],"source":["import sys\n","# Your plot code here\n","history = model.fit(x, y, batch_size=128, epochs=30, callbacks=[print_callback])\n","\n","# Plotting the loss\n","plt.plot(history.history['loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train'], loc='upper left')\n","plt.show()\n"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":491,"status":"ok","timestamp":1715095141891,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"vBFyJ_56KeNi","metadata":{}},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import numpy as np"]},{"cell_type":"code","execution_count":76,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1715096114196,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"2vlP2jYnqBXh","metadata":{}},"outputs":[],"source":["def generate_text(model, char_to_index, indices_char, seed_phrase=\"Hello\", length=500, temperature=0.2):\n","    \"\"\"\n","    Generate text using a trained RNN model.\n","\n","    :param model: Trained Keras model\n","    :param char_to_index: Dictionary mapping characters to their indices\n","    :param indices_char: Dictionary mapping indices to their characters\n","    :param seed_phrase: Initial phrase to start text generation\n","    :param length: Total length of the text to generate\n","    :param temperature: Sampling temperature\n","    \"\"\"\n","    seed_phrase = seed_phrase.lower()\n","    seed_length = len(seed_phrase)\n","    if seed_length < MAXLEN:\n","        # Pad the seed_phrase if it's too short\n","        seed_phrase = seed_phrase.rjust(MAXLEN)\n","    elif seed_length > MAXLEN:\n","        # Truncate the seed_phrase if it's too long\n","        seed_phrase = seed_phrase[:MAXLEN]\n","    # Prepare the seed phrase as the initial input to the model\n","    generated = seed_phrase.lower()\n","    sentence = seed_phrase.lower()\n","\n","    # Generate the text\n","    for i in range(length - len(seed_phrase)):\n","        # Prepare the input tensor\n","        x_pred = np.zeros((1, len(sentence), len(char_to_index)), dtype=np.bool_)\n","        for t, char in enumerate(sentence):\n","            x_pred[0, t, char_to_index[char]] = True\n","\n","        # Make a prediction (output is logits, not probabilities)\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        next_index = sample(preds, temperature)\n","        next_char = indices_char[next_index]\n","\n","        # Append the new character and shift the sentence to include it\n","        generated += next_char\n","        sentence = sentence[1:] + next_char\n","\n","        # Reset the sentence if it gets too long to process (optional)\n","        if len(sentence) > MAXLEN:\n","            sentence = sentence[-MAXLEN:]\n","\n","    return generated\n","\n","def sample(preds, temperature=1.0):\n","    \"\"sentence\" Helper function to sample an index from a probability array \"\"\"\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds + 1e-7) / temperature  # avoid log(0) error\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39392,"status":"ok","timestamp":1715096174884,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"qmcRrIUCqU2j","metadata":{},"outputId":"1e7ad049-4f0e-4953-edf0-272415153c82"},"outputs":[{"ename":"ValueError","evalue":"Exception encountered when calling SimpleRNNCell.call().\n\n\u001b[1mDimensions must be equal, but are 82 and 5316 for '{{node sequential_2_1/simple_rnn_2_1/simple_rnn_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_2_1/simple_rnn_2_1/strided_slice_1, sequential_2_1/simple_rnn_2_1/simple_rnn_cell_1/Cast/ReadVariableOp)' with input shapes: [1,82], [5316,128].\u001b[0m\n\nArguments received by SimpleRNNCell.call():\n  • sequence=tf.Tensor(shape=(1, 82), dtype=float32)\n  • states=('tf.Tensor(shape=(1, 128), dtype=float32)',)\n  • training=False","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[75], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Assume `model`, `char_to_index`, and `indices_char` are already defined\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#generated_text = generate_text(model, char_indices, indices_char, seed_phrase=\"Привет мой друг\", length=500, temperature=0.2)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_text)\n","Cell \u001b[0;32mIn[73], line 32\u001b[0m, in \u001b[0;36mgenerate_text\u001b[0;34m(model, char_to_index, indices_char, seed_phrase, length, temperature)\u001b[0m\n\u001b[1;32m     29\u001b[0m     x_pred[\u001b[38;5;241m0\u001b[39m, t, char_to_index[char]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Make a prediction (output is logits, not probabilities)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m next_index \u001b[38;5;241m=\u001b[39m sample(preds, temperature)\n\u001b[1;32m     34\u001b[0m next_char \u001b[38;5;241m=\u001b[39m indices_char[next_index]\n","File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling SimpleRNNCell.call().\n\n\u001b[1mDimensions must be equal, but are 82 and 5316 for '{{node sequential_2_1/simple_rnn_2_1/simple_rnn_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_2_1/simple_rnn_2_1/strided_slice_1, sequential_2_1/simple_rnn_2_1/simple_rnn_cell_1/Cast/ReadVariableOp)' with input shapes: [1,82], [5316,128].\u001b[0m\n\nArguments received by SimpleRNNCell.call():\n  • sequence=tf.Tensor(shape=(1, 82), dtype=float32)\n  • states=('tf.Tensor(shape=(1, 128), dtype=float32)',)\n  • training=False"]}],"source":["# Example usage:\n","# Assume `model`, `char_to_index`, and `indices_char` are already defined\n","#generated_text = generate_text(model, char_indices, indices_char, seed_phrase=\"Привет мой друг\", length=500, temperature=0.2)\n","generated_text = generate_text(model, char_indices, indices_char, length=500, temperature=0.2)\n","\n","print(generated_text)"]},{"cell_type":"markdown","metadata":{"id":"moISVCNvG18G"},"source":["### More poetic model\n","\n","Let's use LSTM instead of vanilla RNN and compare the results."]},{"cell_type":"markdown","metadata":{"id":"I1Uo-7YAG18G"},"source":["Plot the loss function of the number of epochs. Does the final loss become better?"]},{"cell_type":"code","execution_count":77,"metadata":{"collapsed":true,"executionInfo":{"elapsed":481,"status":"ok","timestamp":1715096481745,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"yOkJgm4UG18G","metadata":{}},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/gitpod/.pyenv/versions/3.12.3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]}],"source":["from tensorflow.keras.layers import LSTM\n","# Your beautiful code here\n","# Build the model: a single LSTM\n","modelLSTM = Sequential([\n","    LSTM(128, input_shape=(MAXLEN, len(chars))),\n","    Dense(len(chars), activation='softmax'),\n","])\n","\n","modelLSTM.compile(loss='categorical_crossentropy', optimizer='adam')"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3011422,"status":"ok","timestamp":1715103483169,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"xzcW0BMRzUwh","metadata":{},"outputId":"413b4a35-516c-4b3a-f291-08cff149f24c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746ms/step - loss: 6.3849\n","----- Generating text after Epoch: 0\n","----- Generating with seed: \"\t\tКак вихорь жизни молодой,\n"," \t\tКружится вальса вихорь шумный;\n"," \t\tЧета мелькает за четой.\n"," \t\tК минуте мщенья приближаясь,\n"," \t\tОнегин, втайне усмехаясь,\n"," \t\tПодходит к Ольге. Быстро с ней\n"," \t\tВертится около гостей,\n"," \t\tПотом на стул ее сажает,\n"," \t\tЗаводит речь о том, о сем;\n"," \t\tСпустя минуты две потом\n"," \t\tВновь с нею вальс он продолжает;\n"," \t\tВсе в изумленье. Ленский сам\n"," \t\tНе верит собственным глазам.\n"," \n"," \n"," \n"," XLII\n"," \n"," \t\tМазурка раздалась. Бывало,\n"," \t\tКогда гремел мазурки гром,\n"," \t\tВ огромной зале всё дрожало,\n"," \t\tПаркет трещал под каблуком,\n"," \t\tТряслися, дребезжали рамы;\n"," \t\tТеперь не то: и мы, как дамы,\n"," \t\tСкользим по лаковым доскам.\n"," \t\tНо в городах, по деревням\n"," \t\tЕще мазурка сохранила\n"," \t\tПервоначальные красы:\n"," \t\tПрипрыжки, каблуки, усы\n"," \t\tВсё те же; их не изменила\n"," \t\tЛихая мода, наш тиран,\n"," \t\tНедуг новейших россиян.\n"," \n"," \n"," \n"," XLIII. XLIV\n"," \n"," \t\tБуянов, братец мой задорный,\n"," \t\tК герою нашему подвел\n"," \t\tТатьяну с Ольгою; проворно\n","\"\n","\t\tКак вихорь жизни молодой,\n"," \t\tКружится вальса вихорь шумный;\n"," \t\tЧета мелькает за четой.\n"," \t\tК минуте мщенья приближаясь,\n"," \t\tОнегин, втайне усмехаясь,\n"," \t\tПодходит к Ольге. Быстро с ней\n"," \t\tВертится около гостей,\n"," \t\tПотом на стул ее сажает,\n"," \t\tЗаводит речь о том, о сем;\n"," \t\tСпустя минуты две потом\n"," \t\tВновь с нею вальс он продолжает;\n"," \t\tВсе в изумленье. Ленский сам\n"," \t\tНе верит собственным глазам.\n"," \n"," \n"," \n"," XLII\n"," \n"," \t\tМазурка раздалась. Бывало,\n"," \t\tКогда гремел мазурки гром,\n"," \t\tВ огромной зале всё дрожало,\n"," \t\tПаркет трещал под каблуком,\n"," \t\tТряслися, дребезжали рамы;\n"," \t\tТеперь не то: и мы, как дамы,\n"," \t\tСкользим по лаковым доскам.\n"," \t\tНо в городах, по деревням\n"," \t\tЕще мазурка сохранила\n"," \t\tПервоначальные красы:\n"," \t\tПрипрыжки, каблуки, усы\n"," \t\tВсё те же; их не изменила\n"," \t\tЛихая мода, наш тиран,\n"," \t\tНедуг новейших россиян.\n"," \n"," \n"," \n"," XLIII. XLIV\n"," \n"," \t\tБуянов, братец мой задорный,\n"," \t\tК герою нашему подвел\n"," \t\tТатьяну с Ольгою; проворно\n"]},{"ename":"KeyError","evalue":"'\\t'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[98], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodelLSTM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Plotting the loss\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","File \u001b[0;32m~/.pyenv/versions/3.12.3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","Cell \u001b[0;32mIn[97], line 64\u001b[0m, in \u001b[0;36mon_epoch_end\u001b[0;34m(epoch, _)\u001b[0m\n\u001b[1;32m     62\u001b[0m x_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, MAXLEN, \u001b[38;5;28mlen\u001b[39m(chars)))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, char \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentence):\n\u001b[0;32m---> 64\u001b[0m     x_pred[\u001b[38;5;241m0\u001b[39m, t, \u001b[43mchar_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m]\u001b[49m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     66\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_pred, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m next_index \u001b[38;5;241m=\u001b[39m sample(preds, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n","\u001b[0;31mKeyError\u001b[0m: '\\t'"]}],"source":["history = modelLSTM.fit(x, y,\n","          batch_size=128,\n","          epochs=20,\n","          callbacks=[print_callback])\n","\n","# Plotting the loss\n","plt.plot(history.history['loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3D66mgieHK9H"},"outputs":[],"source":["# Plotting the loss\n","plt.plot(history.history['loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train'], loc='upper left')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Hvkzh3JpG18H"},"source":["Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n","\n","Evaluate the results visually, try to interpret them."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":442062,"status":"ok","timestamp":1715104116422,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"McPv990UG18H","outputId":"d1b6b902-5b72-456d-a672-245f5502aacb"},"outputs":[],"source":["# Text generation with different temperature values here\n","phrase = 'Which on thy soft cheek for complexion dwells'\n","for temp in [0.1, 0.2, 0.5, 1.0, 1.2]:\n","  print(f\"Temperature: {temp}\")\n","  print('vanilla RNN: ',generate_text(model, char_indices, indices_char, seed_phrase=phrase, length=500, temperature=temp))\n","  print('LSTM: ', generate_text(modelLSTM, char_indices, indices_char, seed_phrase=phrase, length=500, temperature=temp))\n"]},{"cell_type":"markdown","metadata":{"id":"7JtUJwIrG18H"},"source":["### Saving and loading models"]},{"cell_type":"markdown","metadata":{"id":"ZAXZ-iQ7G18H"},"source":["Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":15,"status":"ok","timestamp":1715104116422,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"GVtRA_9tG18H"},"outputs":[],"source":["# Saving and loading code here"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443,"status":"ok","timestamp":1715104232220,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"n-wiN789Krw4","outputId":"b696950c-8d8b-4113-869f-6cb81b2f9bb3"},"outputs":[],"source":["model.save('Shakespeare_sonnets_vanilla_RNN.h5')\n","modelLSTM.save('Shakespeare_sonnets_LSTM.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1076,"status":"ok","timestamp":1715104319905,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"sa3hKDnsLqj0"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","# Load models\n","loaded_vanilla_rnn = load_model('Shakespeare_sonnets_vanilla_RNN.h5')\n","loaded_lstm = load_model('Shakespeare_sonnets_LSTM.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85831,"status":"ok","timestamp":1715104508562,"user":{"displayName":"Dmitrii","userId":"09013314957398390560"},"user_tz":-180},"id":"ZLWJx4qILykK","outputId":"46c2ddca-29ba-4106-da2d-5323be64c54d"},"outputs":[],"source":["phrase1 = 'The sun shine'\n","print('vanilla RNN: ',generate_text(loaded_vanilla_rnn, char_indices, indices_char, seed_phrase=phrase1, length=500, temperature=0.2))\n","print('LSTM: ', generate_text(loaded_lstm, char_indices, indices_char, seed_phrase=phrase1, length=500, temperature=0.2))\n"]},{"cell_type":"markdown","metadata":{"id":"SqYhR6B8G18H"},"source":["### References\n","1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a>\n","There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n","2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n","3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
